{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This code was written to generate the data in the paper \"Ekedahl-Oort Types and Newton Polygons of Abelian Covers\n",
    "of P1 Branched at Three Points\" by Darren Schmidt. Some of the code was taken from https://github.com/jeremybooher/supersingular-3pointed-covers, by Jeremy Booher and Rachel Pries, used and modified with permission. We enumerate every abelian cover of P^1 branched at three points with a given genus, and then compute the natural density of the primes such that the curves are supersingular, superspecial, and where the Newton polygons and Ekedahl-Oort types are unlikely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cmp_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def _partial_enumeration(genus_bound,d,e,f):\n",
    "    \"\"\"Enumerate possible (d,e,f),r,s given (d,e,f).  Used in enumerate_covers\"\"\"\n",
    "    new_stuff = []\n",
    "    r = 1\n",
    "    while r * e * f - (1 + f/d + e/d) <= 2 * genus_bound -2:\n",
    "        if r * e * f - (1 + f/d + e/d) <=0 : #won't have genus > 1\n",
    "            r = r+1\n",
    "            continue\n",
    "        s = 1\n",
    "        while  s * ( r * e * f - (1 + f/d + e/d)) <= 2 * genus_bound - 2:\n",
    "            #is genus an integer?  is s| rd satisfied? are d,e,f pairwise relatively prime\n",
    "            g = s * ( r * e * f - (1 + f/d + e/d)) /2 + 1\n",
    "            if g in ZZ and r * d /s in ZZ and gcd(d,e) == 1 and gcd(d,f) == 1 and gcd(e,f) ==1: \n",
    "                new_stuff.append([[d,e,f],r,s])\n",
    "            s = s+1\n",
    "        r = r+1\n",
    "\n",
    "    return new_stuff\n",
    "\n",
    "\n",
    "def enumerate_covers(genus_bound):\n",
    "    \"\"\"Find all abelian covers of the projective line with three points of ramification and 1<genus <= genus_bound.\n",
    "    Note that requiring genus>1 is fine and removes an infinite family of boring examples of covers\n",
    "    \n",
    "    Returns a list of (d,e,f), s ,r using Ekedahl's notation.\n",
    "    \n",
    "    Note: d,e,f are e_{i,j} in our notation\"\"\"\n",
    "\n",
    "    candidates = []\n",
    "    #remember that d<=e<=f by convention\n",
    "    f = 1\n",
    "    \n",
    "    while f <= 2*genus_bound + 2:\n",
    "        e = 1\n",
    "        \n",
    "        while e <= f:\n",
    "            done_e = true\n",
    "            d = 1 \n",
    "            while d <= e and e * f - (1 + f/d + e/d) <= 2 * genus_bound-2:\n",
    "                new_stuff = _partial_enumeration(genus_bound,d,e,f)\n",
    "                candidates.extend(new_stuff)\n",
    "                d = d +1\n",
    "                \n",
    "            e = e +1        \n",
    "        \n",
    "        f = f +1\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def convert_cover(triple):\n",
    "    \"\"\"Convert to the (a,b,c,s) notation from the (d,e,f), s ,r (both used by Ekedahl).\n",
    "    a,b,c are the orders of the generators of inertia, s is the index of last inertia in G\"\"\"\n",
    "    d,e,f = expand( triple[0])\n",
    "    r = triple[1]\n",
    "    s = triple[2]\n",
    "\n",
    "    a = r * d * e\n",
    "    b = r * d * f\n",
    "    c = r * e * f\n",
    "    genus = s * ( r * e * f - (1 + f/d + e/d)) /2 + 1\n",
    "    \n",
    "    return [a,b,c,s],genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def cyclic_inertial_generators(a,b,c,s):\n",
    "    \"\"\"Assuming the cover has s=1, find possible generators for inertia with given (a,b,c,s).\n",
    "    Prune the list to account for isomorphic covers\"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "    inert_gens = [] #inertial generators to return\n",
    "    isomorphic_gens =[] #cases isomorphic to ones in inert_gens\n",
    "    \n",
    "    # cyclic Galois group is Z/(c)\n",
    "    \n",
    "    order = c*s\n",
    "    G = Integers(order)\n",
    "    #up to automorphism, may as well assume generator for last inertia group is 1\n",
    "    third = G(1)\n",
    "  \n",
    "    #as generators of inertia sum to 0, look at possible values for the first and see which are valid:\n",
    "    #first has order a and second has order b\n",
    "\n",
    "    for g in G:\n",
    "        if g.order() == a and (-third - g ).order() == b:\n",
    "            first = g\n",
    "            second = -third - g\n",
    "\n",
    "            data = [first.lift(),second.lift(),third.lift()]\n",
    "\n",
    "            if data not in isomorphic_gens:\n",
    "                #it's new\n",
    "                inert_gens.append(data)\n",
    "                isomorphic_gens.append(data)\n",
    "\n",
    "                #if some of a,b,c are equal, may permuate and scale to get an isomorphic cover.  Only write down one of them\n",
    "                #in particular, if a=b!= c could swap first and second inertial elements.\n",
    "                #if c = b != a, could swap and rescale\n",
    "                #if c= b= = a, could use S_3 permutation and rescale\n",
    "                if a == b and b != c:\n",
    "                    isomorphic_gens.append([second.lift(),first.lift(),third.lift()])\n",
    "                elif c == b and b != a:\n",
    "                    scaling = second^(-1)\n",
    "                    isomorphic_gens.append([(first*scaling).lift(),scaling.lift(),1])\n",
    "                elif c == b and b == a:\n",
    "                    isomorphic_gens.append([second.lift(),first.lift(),third.lift()])\n",
    "                    isomorphic_gens.append([first^(-1) * second,first^(-1),1])\n",
    "                    isomorphic_gens.append([first^(-1),first^(-1) * second,1])\n",
    "                    isomorphic_gens.append([second^(-1),second^(-1) * first,1])\n",
    "                    isomorphic_gens.append([second^(-1) * first,second^(-1),1])\n",
    "                    \n",
    "    return inert_gens,order\n",
    "\n",
    "def alternate_inertial_generators(a,b,c,s):\n",
    "    \"\"\"The cover is a product Z/(i) \\times Z/(j) with j|i and ij = cs,\n",
    "    find possible generators for inertia (up to automorphism) with given (a,b,c,s)\"\"\"\n",
    "\n",
    "    inert_gen_list = []\n",
    "    order = c * s\n",
    "    \n",
    "    # Galois group is Z/(c) \\times Z/(s) \n",
    "    if s.divides(a) and a.divides(b) and b.divides(c):\n",
    "        \n",
    "        \n",
    "        \n",
    "        G = AdditiveAbelianGroup([c,s])\n",
    "        inert_gens = [G]\n",
    "        #up to automorphism, may as well assume generator for last inertia group is (1,0) as it has order c\n",
    "        third = G([1,0])\n",
    "        c0 = [1,0]\n",
    "        #the other two generators cannot lie in <(1,0)> as they together generate the whole group.\n",
    "\n",
    "        #as generators of inertia sum to 0, look at possible values for the first and see which are valid:\n",
    "        #first has order a and second has order b\n",
    "        \n",
    "        R1 = Integers(c)\n",
    "        R2 = Integers(s)\n",
    "\n",
    "        for i in range(c):\n",
    "\n",
    "            for j in range(s):\n",
    "                \n",
    "                secondElement = [i,j]\n",
    "                thirdElement = [R1(-1-i).lift(),R2(-j).lift()]\n",
    "                secondOrder = lcm(c/gcd(i,c),s/gcd(j,s))\n",
    "                thirdOrder = lcm(c/gcd(c,thirdElement[0]),s/gcd(s,thirdElement[1]))\n",
    "                if secondOrder == a and thirdOrder == b:\n",
    "                    if G.submodule([third, G(secondElement)]).order() == c*s:\n",
    "                        inert_gens.append([secondElement,thirdElement,c0])\n",
    "                        \n",
    "        inert_gen_list.append(inert_gens)\n",
    "\n",
    "    #Not guaranteed to be Z/(c) \\times Z/(s), loops through all possible groups that it could be\n",
    "    else:\n",
    "        \n",
    "        lcmGroup = lcm(a,lcm(b,c))\n",
    "        for i in range(1, floor(order/lcmGroup)+1):\n",
    "            #Constructs group of size Z/(j) \\times Z/(k) with k | j and kj = cs\n",
    "            j = i * lcmGroup\n",
    "            if j.divides(order):\n",
    "                k = Integer(order/j)\n",
    "                if k.divides(j):\n",
    "                    R1 = Integers(j)\n",
    "                    R2 = Integers(k)\n",
    "                    G = AdditiveAbelianGroup([j,k])\n",
    "                    inert_gens = [G]\n",
    "                    \n",
    "                    #Need three elements of G with order a, b, and c such that their sum is 0 and any two of them generate G.\n",
    "                    #If j == c, can choose (1,0) in G as third element.\n",
    "                    if j == c:\n",
    "                        third = G([1,0])\n",
    "                        c0 = [1,0]\n",
    "                        \n",
    "                        #If k == a, can choose (0,1) as first element. Then find possible second element with order b.\n",
    "                        if k == a:\n",
    "                        \n",
    "                            first = G([0,1])\n",
    "                            secondElement = [0,1]\n",
    "\n",
    "                            thirdElement = [R1(-c0[0]).lift(), R2(-c0[1]-1).lift()]\n",
    "                            thirdOrder = lcm(j/gcd(j,thirdElement[0]),k/gcd(k,thirdElement[1]))\n",
    "\n",
    "                            if thirdOrder == b:\n",
    "                                inert_gens.append([secondElement,thirdElement,c0])\n",
    "\n",
    "                            inert_gen_list.append(inert_gens)\n",
    "                    \n",
    "                \n",
    "                        else:\n",
    "                        #Otherwise, need to find any other generators that work\n",
    "                            for m in range(j):\n",
    "                                for n in range(k):\n",
    "                                \n",
    "                                    secondElement = [m,n]\n",
    "                                    thirdElement = [R1(-c0[0]-m).lift(),R2(-c0[1]-n).lift()]\n",
    "                                    secondOrder = lcm(j/gcd(m,j),k/gcd(n,k))\n",
    "                                    thirdOrder = lcm(j/gcd(j,thirdElement[0]),k/gcd(k,thirdElement[1]))\n",
    "                                    if secondOrder == a and thirdOrder == b:\n",
    "                                        if G.submodule([third, G(secondElement)]).order() == c*s:\n",
    "                                            inert_gens.append([secondElement,thirdElement,c0])\n",
    "                            inert_gen_list.append(inert_gens)\n",
    "                        \n",
    "                    else:\n",
    "                        #Need to loop through all possible generators for G with needed properties\n",
    "                        for m in range(j):\n",
    "                            for n in range(k):\n",
    "                                if lcm(j/gcd(j,m),k/gcd(k,n)) == c:\n",
    "                                    c0 = [m,n]\n",
    "                                    third = G(c0)\n",
    "                                    \n",
    "                                    \n",
    "                                    if k == a:\n",
    "                        \n",
    "                                        first = G([0,1])\n",
    "                                        secondElement = [0,1]\n",
    "\n",
    "                                        thirdElement = [R1(-c0[0]).lift(), R2(-c0[1]-1).lift()]\n",
    "                                        thirdOrder = lcm(j/gcd(j,thirdElement[0]),k/gcd(k,thirdElement[1]))\n",
    "\n",
    "                                        if thirdOrder == b:\n",
    "                                            inert_gens.append([secondElement,thirdElement,c0])\n",
    "\n",
    "                                        inert_gen_list.append(inert_gens)\n",
    "                                        \n",
    "                                    else:\n",
    "                                        for m in range(j):\n",
    "                                            for n in range(k):\n",
    "                                \n",
    "                                                secondElement = [m,n]\n",
    "                                                thirdElement = [R1(-c0[0]-m).lift(),R2(-c0[1]-n).lift()]\n",
    "                                                secondOrder = lcm(j/gcd(m,j),k/gcd(n,k))\n",
    "                                                thirdOrder = lcm(j/gcd(j,thirdElement[0]),k/gcd(k,thirdElement[1]))\n",
    "                                                if secondOrder == a and thirdOrder == b:\n",
    "                                                    if G.submodule([third, G(secondElement)]).order() == c*s:\n",
    "                                                        inert_gens.append([secondElement,thirdElement,c0])\n",
    "                  \n",
    "                                        inert_gen_list.append(inert_gens)\n",
    "                        \n",
    "                 \n",
    "        \n",
    "                \n",
    "    \n",
    "    return inert_gen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def present_by_genus(min,max):\n",
    "    \"\"\"Create dictionaries of all covers where min <= genus <= max, indexed by genus\"\"\"\n",
    "    data  = enumerate_covers(max)\n",
    "\n",
    "    collected_covers = {} #(a,b,c,s)\n",
    "    for n in range(min,max+1):\n",
    "        collected_covers[n] = []\n",
    "\n",
    "    for triple in data:\n",
    "        data,genus = convert_cover(triple)\n",
    "        if min <= genus and genus <= max:\n",
    "            collected_covers[genus].append(data)\n",
    "\n",
    "    return collected_covers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#auxiliary functions\n",
    "def compute_fj(j,a1,a2,a3,m):\n",
    "    return -1 + frac(-1 * j * a1/m) + frac(-1 * j * a2/m) + frac(-1 * j * a3/m)\n",
    "\n",
    "def compute_dj(j,m):\n",
    "    return ((Integers(m))(j)).order() #it is additive order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def compare_words(a,b):\n",
    "    \"\"\"Lexicographic comparison of words in F and V of same length with F < V\"\"\"\n",
    "    #Returns 1 if a < b and -1 if a > b\n",
    "    for i in range(len(a)):\n",
    "        if a[i] == \"F\" and b[i] == \"V\":\n",
    "            return 1\n",
    "        if a[i] == \"V\" and b[i] == \"F\":\n",
    "            return -1\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def all_cycles(w,k):\n",
    "    \"\"\"Given a word w, left shifts the word k-times\"\"\"\n",
    "    return w[k:] + w[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def canonical_type(W):\n",
    "    \"\"\"Computes the canonical type, a precursor to computing the final type, a representative of the Ekedahl-Oort type\"\"\"\n",
    "    \n",
    "    unique_words = []\n",
    "    multiplicity = []\n",
    "    length = []\n",
    "    unique_cycles = []\n",
    "    \n",
    "    #Gathers all the unique words that appear up to shifting of words\n",
    "    #Also gathers the length and multiplicity of all these unique words\n",
    "    letterCount = 0\n",
    "    index_count = -1\n",
    "    for w in W:\n",
    "        for a in w:\n",
    "            letterCount += 1\n",
    "        if w not in unique_words:\n",
    "            unique_words.append(w)\n",
    "            multiplicity.append(1)\n",
    "            length.append(len(w))\n",
    "            index_count += 1\n",
    "        else:\n",
    "            index = unique_words.index(w)\n",
    "            multiplicity[index] += 1\n",
    "            \n",
    "    #Need to make all words the same length by raising them to a power. This gives the smallest power that works for all words\n",
    "    word_length = lcm(length)\n",
    "\n",
    "    eoType = [-1 for i in range(letterCount/2)]\n",
    "    \n",
    "    #For all unique words that appear, give every possible cycle using those same letters and raises them to a power to get them to be the same length\n",
    "    for i in range(len(unique_words)):\n",
    "        cycles = [all_cycles(unique_words[i], j)*(int(word_length/length[i])) for j in range(length[i])]\n",
    "        unique_cycles.append(cycles)\n",
    "\n",
    "    #Sorts the words in lexicographical order with F<V\n",
    "    sorted_words = sorted([w for words in unique_cycles for w in words], key=cmp_to_key(compare_words), reverse=True)\n",
    "    \n",
    "    #tau stores the dimension of the subspace in the canonical filtration corresponding to each word\n",
    "    tau = []\n",
    "    for i in range(len(unique_words)):\n",
    "        for j in range(length[i]):\n",
    "            for k in range(multiplicity[i]):\n",
    "                w = unique_cycles[i][j]# * int(word_length/length[i])\n",
    "                tau.append([sorted_words.index(w),i,j])\n",
    "    \n",
    "    #Final type is a non-decreasing list of non-negative integers of length g, where g is the genus of the curve.\n",
    "    #The canonical type at the i-th spot is the dimension of Frobenius F applied to the subspace associated to the word with dimension i as a vector space\n",
    "    dim = []\n",
    "    for i in range(1,len(sorted_words)+1):\n",
    "        n = 0\n",
    "        basisList = []\n",
    "        eoCount = 0\n",
    "        for t in tau:\n",
    "            if t[0] <= i-1:\n",
    "                w = unique_words[t[1]]\n",
    "                \n",
    "                if w[length[t[1]] - t[2] - 1] == \"F\":\n",
    "                    eoCount+=1\n",
    "                        \n",
    "                n += 1\n",
    "        if n <= letterCount/2:\n",
    "            eoType[n-1] = eoCount\n",
    "\n",
    "    return eoType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def final_type(eoType):\n",
    "    \"\"\"Takes canonical type and fills in the blanks to return the final type\"\"\"\n",
    "    last = 0\n",
    "    thisRun = []\n",
    "\n",
    "    #The canonical type has some 0's. This computes the final filtration and fills in the dimension of F applied to each subspace\n",
    "    for i in range(len(eoType)):\n",
    "        if eoType[i] == -1:\n",
    "            thisRun.append(i)\n",
    "        else:\n",
    "            for j in range(len(thisRun)):\n",
    "                if eoType[i] == last:\n",
    "                    eoType[i-j-1] = last\n",
    "                else:\n",
    "                    eoType[i-j-1] = eoType[i] - j - 1\n",
    "            last = eoType[i]\n",
    "            thisRun = []\n",
    "\n",
    "    return eoType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def eo_dimension(eoType):\n",
    "    \"\"\"Computes dimension of locus of A_g with given EO-type, which is the sum of the numbers in the final type.\"\"\"\n",
    "    summation = 0\n",
    "    for a in eoType:\n",
    "        summation += a\n",
    "    return summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def np_dimension(slopes):\n",
    "    \"\"\"Computes dimension of locus of A_g with given symmetric Newton polygon\"\"\" \n",
    "    #Dimension is number of lattice points above or on Newton polygon and below line y=x\n",
    "    g = len(slopes)/2\n",
    "    \n",
    "    yVal = 0\n",
    "    dim = 0\n",
    "    for i in range(g):\n",
    "\n",
    "        yVal += slopes[i]\n",
    "\n",
    "        for j in range(ceil(yVal), i+1):\n",
    "            if (j < i+1 and j <= g):\n",
    "                dim += 1\n",
    "            \n",
    "    return dim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#there is probably a way to get the orbits using built-in methods, but it's also easy to do directly\n",
    "def find_orbits(p,m):\n",
    "    \"\"\"Find the orbits of the multiplication by p map on Z/mZ - {0}\"\"\"\n",
    "    G = Integers(m)\n",
    "    used_elements = {G(0)} \n",
    "    orbits = {G(0)}\n",
    "    orbits.remove(G(0)) #don't want the trivial orbit\n",
    "\n",
    "    for g in G:\n",
    "        if g not in used_elements:\n",
    "            new_orbit = [g]\n",
    "            current = p * g\n",
    "            while current != g:\n",
    "                new_orbit.append(current)\n",
    "                used_elements.add(current)\n",
    "                current = p * current\n",
    "            orbits.add(tuple(new_orbit))\n",
    "\n",
    "    return orbits\n",
    "\n",
    "def compute_slopes(p,a1,a2,a3,m):\n",
    "    \"\"\"Computes the slopes, returing a list of the G_{c,d} appearing in the decomposition\"\"\"\n",
    "    orbits = find_orbits(p,m)\n",
    "    slopes = []\n",
    "    lineSlopes = []\n",
    "\n",
    "    for orbit in orbits:\n",
    "        j = orbit[0]\n",
    "        dj = compute_dj(j,m)\n",
    "        if a1 % dj != 0 and a2 % dj != 0 and a3 % dj != 0:\n",
    "            ones = sum([compute_fj(n.lift(),a1,a2,a3,m) for n in orbit])\n",
    "            slopes.append((ones,len(orbit)-ones))\n",
    "            for k in range(len(orbit)):\n",
    "                lineSlopes.append(ones/len(orbit))\n",
    "    \n",
    "    return slopes,sorted(lineSlopes) \n",
    "\n",
    "def is_supersingular(p,a1,a2,a3,m):\n",
    "    \"\"\"Is the cover of degree m with inertial generators a1,a2,a3 supersingular in characteristic p?  Note depends only on p modulo m\"\"\"\n",
    "    slopes = compute_slopes(p,a1,a2,a3,m)[0]\n",
    "\n",
    "    for chunk in slopes:\n",
    "        if chunk[1] != 0 and chunk[0]/chunk[1] != 1: #equivalent to slope 1/2\n",
    "            return false\n",
    "\n",
    "    return true\n",
    "\n",
    "def is_ul_newton(p,a1,a2,a3,m, multiplier):\n",
    "    \"\"\"Does the Newton polygon of cover of degree m with inertial generators a1,a2,a3 represent an unlikely intersection in characteristic p?  Note depends only on p modulo m\"\"\"\n",
    "    #multiplier is used when looking for \n",
    "    slopes = compute_slopes(p,a1,a2,a3,m)[1]\n",
    "    moduli_dim = moduliDimension(slopes)\n",
    "    g = len(slopes)/2\n",
    "    \n",
    "    #Codimension of locus of abelian varieties in A_g with given Newton polygon > multiplier*(dim of M_g) \n",
    "    if g*(g+1)/2 - moduli_dim > multiplier* (3*g-3):\n",
    "        return true\n",
    "\n",
    "    return false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def find_supersingular(a1,a2,a3,m):\n",
    "    \"\"\"Find all congruence class of primes modulo m (with gcd(p,m)=1) such that the cover is supersingular\"\"\"\n",
    "    congruence_classes = dict()\n",
    "    for p in range(m):\n",
    "        if gcd(p,m) == 1:\n",
    "            if is_supersingular(p,a1,a2,a3,m):\n",
    "                congruence_classes[p] = 0\n",
    "    return congruence_classes\n",
    "\n",
    "def find_ul_newton(a1,a2,a3,m):\n",
    "    \"\"\"Find all congruence class of primes modulo m (with gcd(p,m)=1) such that the cover has an unlikely Newton polygon\"\"\"\n",
    "    congruence_classes = dict()\n",
    "    for p in range(m):\n",
    "        if gcd(p,m) == 1:\n",
    "            if is_ul_newton(p,a1,a2,a3,m):\n",
    "                congruence_classes[p] = 0\n",
    "    return congruence_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def computeType(c0,s,aList,mList,d,e):\n",
    "    \"\"\"Computes the signature type using the Chevalley-Weil formula\"\"\"\n",
    "    sigType = -1\n",
    "    for i in range(len(mList)):\n",
    "        R = Integers(mList[i])\n",
    "        term = 2*d*aList[i][0]+2*e*aList[i][1]*(c0/s)\n",
    "        term = term/c0 * mList[i]\n",
    "        term = Integer(R(term/2))\n",
    "        fraction = -term/mList[i]\n",
    "        sigType += fraction - floor(fraction)\n",
    "    return sigType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def computeOrbits(c0,s,p):\n",
    "    \"\"\"Computes the orbits of the elements of Z/c0 \\times Z/s by the action of multiplication by p\"\"\"\n",
    "    Rc = Integers(c0)\n",
    "    Rs = Integers(s)\n",
    "    orbitList = []\n",
    "    newOrbit = True\n",
    "    for i in range(0,c0):\n",
    "        for j in range(0,s):\n",
    "            for o in orbitList:\n",
    "                if [i,j] in o:\n",
    "                    newOrbit = False\n",
    "            if newOrbit:\n",
    "                orbit = [[i,j]]\n",
    "                notInOrbit = True\n",
    "                \n",
    "                while notInOrbit:\n",
    "                    iNew = Integer(Rc(i*p))\n",
    "                    jNew = Integer(Rs(j*p))\n",
    "                    if [iNew, jNew] in orbit:\n",
    "                        notInOrbit = False\n",
    "                        break\n",
    "                    orbit.append([iNew,jNew])\n",
    "                    i = iNew\n",
    "                    j = jNew\n",
    "                orbitList.append(orbit)\n",
    "            newOrbit = True\n",
    "    return orbitList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def computeKernel(c0,s,a,b):\n",
    "    \"\"\"Computes the kernel of the function f: Z/c0 \\times Z/s \\to \\mathbb{C} where f(x,y) = \\zeta_(c_0)^(ax)*\\zeta_s^(by), where \\zeta_b is\n",
    "    a primitive b-th root of unity.\"\"\"\n",
    "    kernel = set(())\n",
    "    R = Integers(c0)\n",
    "    for i in range(0,c0):\n",
    "        for j in range(0,s):\n",
    "            if R(a*i + b*j*c0/s) == 0:\n",
    "                kernel.add((i,j))\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def quotientInertiaType(a,character,c0,s,n):\n",
    "    \"\"\"Computes the inertia type of a curve quotiented by the kernel of a function as above\"\"\"\n",
    "    newInertiaType = []\n",
    "    R = Integers(n)\n",
    "    for b in a:\n",
    "        inertia = Integer(R(n/c0*(b[0]*character[0] + b[1]*character[1]*c0/s)))\n",
    "        if inertia != 0:\n",
    "            newInertiaType.append(inertia)\n",
    "    return newInertiaType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def shimuraTaniyama(inertia,ramification,p,groupSize):\n",
    "    \"\"\"Given an abelian cover of P^1 branched at three points, computes the slopes of the Newton polygon using the Shimura-Taniyama formula\"\"\"\n",
    "    characters = []\n",
    "    slopes = []\n",
    "    characterKernels = []\n",
    "\n",
    "    #Grabs the characters with signature type 1\n",
    "    for i in range(groupSize[0]):\n",
    "        for j in range(groupSize[1]):\n",
    "            if i != 0 or j != 0:\n",
    "                sigType = computeType(groupSize[0],groupSize[1],inertia,ramification[:len(ramification)-1],i,j)\n",
    "                if sigType == 1:\n",
    "                    characters.append([i,j])\n",
    "                    kernel = computeKernel(groupSize[0],groupSize[1],i,j)\n",
    "                    characterKernels.append(kernel)\n",
    "\n",
    "    orbits = computeOrbits(groupSize[0],groupSize[1],p)\n",
    "\n",
    "    #For every orbit by the action of multiplication by p, we quotient the curve by the kernel of an element in the orbit.\n",
    "    for orbit in orbits:\n",
    "        slope = 0\n",
    "        kernel = computeKernel(groupSize[0],groupSize[1],orbit[0][0],orbit[0][1])\n",
    "        print(orbit)\n",
    "        isGenus0 = True\n",
    "        \n",
    "        for i in range(len(characters)):\n",
    "            if kernel.issubset(characterKernels[i]):\n",
    "                isGenus0 = False\n",
    "                break\n",
    "\n",
    "        #If we don't have the trivial case, the quotient curve is a cyclic cover of P^1 branched at three points, so we can apply\n",
    "        #the Shimura-Taniyama formula to compute the slopes\n",
    "        if not isGenus0:\n",
    "\n",
    "            \n",
    "            qGroupSize = groupSize[0]*groupSize[1]/len(kernel)\n",
    "\n",
    "            newInertia = quotientInertiaType(inertia,orbit[0],groupSize[0],groupSize[1],qGroupSize)\n",
    "            R = Integers(qGroupSize)\n",
    "            print(newInertia)\n",
    "            \n",
    "            if newInertia != []:\n",
    "                addSig = True\n",
    "\n",
    "                x = qGroupSize/groupSize[0]*orbit[0][0]\n",
    "                y = qGroupSize/groupSize[1]*orbit[0][1]\n",
    "                \n",
    "                if x != 0 or y != 0:\n",
    "                    order = Integer(lcm(gcd(x,y),qGroupSize)/gcd(x,y))\n",
    "                else:\n",
    "                    order = 1\n",
    "\n",
    "                for i in newInertia:\n",
    "                    print(i,order)\n",
    "                    if order.divides(i):\n",
    "\n",
    "                        addSig=False\n",
    "                if addSig:\n",
    "                    \n",
    "                    for c in orbit:\n",
    "                        if c in characters:\n",
    "                            slope += 1\n",
    "                    for i in range(len(orbit)):\n",
    "\n",
    "                        slopes.append(slope/len(orbit))\n",
    "                print()\n",
    "        \n",
    "    return p,sorted(slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def _compute_moduli(moduli_dict):\n",
    "    \"\"\"Given the exponents of every galois group of a curve with genus g, and a list of primes, computes the natural density\n",
    "    of the set of primes contained in the set of all primes. If the computation takes too long, it cuts it off and does an underestimate.\"\"\"\n",
    "    \n",
    "    modulus_list = moduli_dict.keys()\n",
    "    prime_occurence_list = []\n",
    "    new_modulus_list = []\n",
    "\n",
    "    #Since some examples are  too big to compute, we put the moduli with the most congruence classes first.\n",
    "    for modulus in modulus_list:\n",
    "        dictLength = len(moduli_dict[modulus])\n",
    "        if dictLength > 0:\n",
    "            prime_occurence_list.append(dictLength/modulus)\n",
    "            new_modulus_list.append(modulus)\n",
    "    sorted_modulus_list = [x for _, x in sorted(zip(prime_occurence_list, new_modulus_list), reverse=True)]\n",
    "    \n",
    "    if sorted_modulus_list == []:\n",
    "        return 0\n",
    "    \n",
    "    m = sorted_modulus_list[0]\n",
    "    new_modulus_list = [m]\n",
    "    underestimate = False\n",
    "    for modulus in sorted_modulus_list[1:]:\n",
    "        \n",
    "        new_lcm = lcm(m,modulus)\n",
    "        #This value is somewhat arbitrary, we noticed that around this value for the lcm, the computation took much longer.\n",
    "        if new_lcm <= 200000000:\n",
    "            m = new_lcm\n",
    "            new_modulus_list.append(modulus)\n",
    "        else:\n",
    "            underestimate = True\n",
    "    if underestimate:\n",
    "        print(\"Underestimate\")\n",
    "    num_moduli = 0\n",
    "    \n",
    "    print(m)\n",
    "    \n",
    "    for i in range(1,m):\n",
    "        if gcd(i,m) == 1:\n",
    "            for modulus in new_modulus_list:\n",
    "                if i % modulus in moduli_dict[modulus]:\n",
    "                    num_moduli += 1\n",
    "                    break\n",
    "    \n",
    "    \n",
    "    return num_moduli/euler_phi(m)    \n",
    "\n",
    "def compute_densities(min,max):\n",
    "    \"\"\"Compute the density of primes for which we have supersingular 3-pointed covers with min <= genus <= max.\n",
    "    Relies on non_cyclic_congruences[g] being non-empty (i.e. we worked out what happens when s != 1).\n",
    "    If empty, just analyzes the cyclic examples.\"\"\"\n",
    "\n",
    "    collected_covers = present_by_genus(min,max)\n",
    "    data_by_genus = []\n",
    "    \n",
    "    \n",
    "    for g in range(min,max+1):\n",
    "        print(g)\n",
    "        moduli_dict = dict()\n",
    "\n",
    "        #Loops through all covers of genus g.\n",
    "        for data in collected_covers[g]:\n",
    "            if data[3] == 1: #will be cyclic\n",
    "                z = data # [a,b,c,s]\n",
    "                possible_gens,m = cyclic_inertial_generators(*data)\n",
    "                if not m in moduli_dict:\n",
    "                    moduli_dict[m] = dict()\n",
    "                for alist in possible_gens:\n",
    "                    moduli_dict[m].update(find_supersingular(*alist,m))\n",
    "            else:\n",
    "                \n",
    "                gen_list = alternate_inertial_generators(*data)\n",
    "                for gen in gen_list:\n",
    "                    groupSize = list(gen[0].invariants())\n",
    "                    groupSize.reverse()\n",
    "                    \n",
    "                    if len(groupSize) == 1:\n",
    "                        groupSize.append(1)\n",
    "                    \n",
    "                    groupOrder = groupSize[0]*groupSize[1]\n",
    "                    \n",
    "                    if not groupSize[0] in moduli_dict:\n",
    "                        moduli_dict[groupSize[0]] = dict()\n",
    "\n",
    "                    #Grabs the slopes for all covers and records whether or not it is supersingular\n",
    "                    for i in range(1,len(gen)):\n",
    "                        for j in range(1,groupSize[0]):\n",
    "                            if gcd(j,groupSize[0]) == 1:\n",
    "                                slopeData = shimuraTaniyama(gen[i],data,j,groupSize)\n",
    "                                prime = slopeData[0]\n",
    "                                slopes = slopeData[1]\n",
    "                                \n",
    "                                supersingular = True\n",
    "                                for slope in slopes:\n",
    "                                    if slope != 1/2:\n",
    "                                        supersingular = False\n",
    "                                        break\n",
    "                               \n",
    "                                if supersingular:\n",
    "                                    moduli_dict[groupSize[0]].update({prime: 0})\n",
    "        print(\"Analyzing density\")\n",
    "        density = _compute_moduli(moduli_dict)\n",
    "\n",
    "        data_by_genus.append(density)\n",
    "        print(g,density)\n",
    "        print(\"\")\n",
    "    return data_by_genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def cycle_word(w):\n",
    "    \"\"\"Given a word in the characters F and V, returns all cycles of that word\"\"\"   \n",
    "    a = w\n",
    "    if a[0] == \"F\" and a[-1] == \"V\":\n",
    "        return a\n",
    "    for i in range(1,len(w)):\n",
    "        a = w[i:] + w[:i]\n",
    "        \n",
    "        if a[0] == \"F\" and a[-1] == \"V\":\n",
    "            return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def ekedahl_oort_type(inertia, ramification, p, groupSize):\n",
    "    \"\"\"In a similar vein to the Shimura-Taniyama function, this computes the Ekedahl-Oort type by taking quotients of the curve\"\"\"\n",
    "    characters = []\n",
    "    words = []\n",
    "    characterKernels = []\n",
    "    \n",
    "    for i in range(groupSize[0]):\n",
    "        for j in range(groupSize[1]):\n",
    "            if i != 0 or j != 0:\n",
    "                sigType = computeType(groupSize[0],groupSize[1],inertia,ramification[:len(ramification)-1],i,j)\n",
    "                if sigType == 1:\n",
    "                    characters.append([i,j])\n",
    "                    kernel = computeKernel(groupSize[0],groupSize[1],i,j)\n",
    "                    characterKernels.append(kernel)\n",
    "\n",
    "    orbits = computeOrbits(groupSize[0],groupSize[1],p)\n",
    "    \n",
    "    for orbit in orbits:\n",
    "        \n",
    "        slope = 0\n",
    "        kernel = computeKernel(groupSize[0],groupSize[1],orbit[0][0],orbit[0][1])\n",
    "\n",
    "        isGenus0 = True\n",
    "        \n",
    "        for i in range(len(characters)):\n",
    "            if kernel.issubset(characterKernels[i]):\n",
    "                isGenus0 = False\n",
    "                break\n",
    "        \n",
    "        if not isGenus0:\n",
    "\n",
    "            word = \"\"\n",
    "            fAppears = False\n",
    "            vAppears = False\n",
    "            for character in orbit:\n",
    "                conjugate = [(groupSize[0] - character[0]) % groupSize[0], (groupSize[1] - character[1]) % groupSize[1]]\n",
    "                if conjugate in characters:\n",
    "                    word += \"F\"\n",
    "                    fAppears = True\n",
    "                else:\n",
    "                    word += \"V\"\n",
    "                    vAppears = True\n",
    "            if fAppears and vAppears:\n",
    "                words.append(cycle_word(word))\n",
    "            else:\n",
    "                words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def superspecial(words):\n",
    "    \"\"\"Returns true if the only words given by a curve are 'FV'\"\"\"\n",
    "    for word in words:\n",
    "        if word != \"FV\":\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def eo_prime_density(min, max):\n",
    "    \"\"\"Computes the density of primes such that there is a superspecial curve per genus, with genus in between min and max\"\"\"\n",
    "    collected_covers = present_by_genus(min,max)\n",
    "    data_by_genus = []\n",
    "    \n",
    "    \n",
    "    for g in range(min,max+1):\n",
    "        print(g)\n",
    "        moduli_dict = dict()\n",
    "        \n",
    "        for data in collected_covers[g]:\n",
    "            if data[3] == 1: #will be cyclic\n",
    "                z = data # [a,b,c,s]\n",
    "                possible_gens,m = cyclic_inertial_generators(*data)\n",
    "                groupSize = [m,1]\n",
    "\n",
    "                new_gens = []\n",
    "                for gens in possible_gens:\n",
    "                    new_gens.append([[gens[0],1],[gens[1],1],[gens[2],1]])\n",
    "                if not m in moduli_dict:\n",
    "                    moduli_dict[m] = dict()\n",
    "                for gen in new_gens:\n",
    "                    for i in range(1,m):\n",
    "                        if gcd(i,m) == 1:\n",
    "                            eoType = ekedahl_oort_type(gen,data,i,groupSize)\n",
    "                            if superspecial(eoType):\n",
    "                                if not i in moduli_dict[m]:\n",
    "                                    moduli_dict[m][i] = dict()\n",
    "                                \n",
    "                                moduli_dict[m][i] = 0\n",
    "            else:\n",
    "                \n",
    "                gen_list = alternate_inertial_generators(*data)\n",
    "                for gen in gen_list:\n",
    "                    groupSize = list(gen[0].invariants())\n",
    "                    groupSize.reverse()\n",
    "                    \n",
    "                    if len(groupSize) == 1:\n",
    "                        groupSize.append(1)\n",
    "                    \n",
    "                    groupOrder = groupSize[0]*groupSize[1]\n",
    "                    \n",
    "                    if not groupSize[0] in moduli_dict:\n",
    "                        moduli_dict[groupSize[0]] = dict()\n",
    "                    \n",
    "                    for i in range(1,len(gen)):\n",
    "                        for j in range(1,groupSize[0]):\n",
    "                            if gcd(j,groupSize[0]) == 1:\n",
    "                                \n",
    "                                eoType = ekedahl_oort_type(gen[i],data,j,groupSize)\n",
    "                                if superspecial(eoType):\n",
    "                                    if not j in moduli_dict[groupSize[0]]:\n",
    "                                        moduli_dict[groupSize[0]][j] = dict()\n",
    "                                \n",
    "                                    moduli_dict[groupSize[0]][j] = 0\n",
    "        print(\"Analyzing density\")\n",
    "\n",
    "        density = _compute_moduli(moduli_dict)\n",
    "\n",
    "        data_by_genus.append(density)\n",
    "        print(g,density)\n",
    "        print(\"\")\n",
    "    return data_by_genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def ul_newton_prime_density(min, max):\n",
    "    \"\"\"Computes the density of primes such that the covers have an unlikely Newton polygon per genus, with genus in between min and max\"\"\"\n",
    "    collected_covers = present_by_genus(min,max)\n",
    "    data_by_genus = []\n",
    "    \n",
    "    \n",
    "    for g in range(min,max+1):\n",
    "        print(g)\n",
    "        moduli_dict = dict()\n",
    "        \n",
    "        for data in collected_covers[g]:\n",
    "            if data[3] == 1: #will be cyclic\n",
    "                z = data # [a,b,c,s]\n",
    "                possible_gens,m = cyclic_inertial_generators(*data)\n",
    "                if not m in moduli_dict:\n",
    "                    moduli_dict[m] = dict()\n",
    "                for alist in possible_gens:\n",
    "                    moduli_dict[m].update(find_ul_newton(*alist,m))\n",
    "            else:\n",
    "                \n",
    "                gen_list = alternate_inertial_generators(*data)\n",
    "                for gen in gen_list:\n",
    "                    groupSize = list(gen[0].invariants())\n",
    "                    groupSize.reverse()\n",
    "                    \n",
    "                    if len(groupSize) == 1:\n",
    "                        groupSize.append(1)\n",
    "                    \n",
    "                    groupOrder = groupSize[0]*groupSize[1]\n",
    "                    \n",
    "                    if not groupSize[0] in moduli_dict:\n",
    "                        moduli_dict[groupSize[0]] = dict()\n",
    "                    \n",
    "                    for i in range(1,len(gen)):\n",
    "                        for j in range(1,groupSize[0]):\n",
    "                            if gcd(j,groupSize[0]) == 1:\n",
    "                                slopeData = shimuraTaniyama(gen[i],data,j,groupSize)\n",
    "                                #print(slopeData)\n",
    "                                prime = slopeData[0]\n",
    "                                modDim = moduliDimension(slopeData[1])\n",
    "                                if g*(g+1)/2 - modDim > 2*(3*g-3):\n",
    "                                    moduli_dict[groupSize[0]].update({prime:0})\n",
    "\n",
    "        print(\"Analyzing density\")\n",
    "        density = _compute_moduli(moduli_dict)\n",
    "        #print(combined)\n",
    "        #print(common_modulus)\n",
    "\n",
    "        data_by_genus.append(density)\n",
    "        print(g,density)\n",
    "        print(\"\")\n",
    "    return data_by_genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def eo_ul_density(min, max):\n",
    "    \"\"\"Computes the density of primes such that the covers have an unlikely Ekedahl-Oort type per genus, with genus in between min and max\"\"\"\n",
    "    collected_covers = present_by_genus(min,max)\n",
    "    data_by_genus = []\n",
    "    \n",
    "    \n",
    "    for g in range(min,max+1):\n",
    "        print(g)\n",
    "        moduli_dict = dict()\n",
    "        \n",
    "        for data in collected_covers[g]:\n",
    "          \n",
    "            if data[3] == 1: #will be cyclic\n",
    "                z = data # [a,b,c,s]\n",
    "                possible_gens,m = cyclic_inertial_generators(*data)\n",
    "                groupSize = [m,1]\n",
    "\n",
    "                new_gens = []\n",
    "                for gens in possible_gens:\n",
    "                    new_gens.append([[gens[0],1],[gens[1],1],[gens[2],1]])\n",
    "                if not m in moduli_dict:\n",
    "                    moduli_dict[m] = dict()\n",
    "                for gen in new_gens:\n",
    "                 \n",
    "                    for i in range(1,m):\n",
    "                        if gcd(i,m) == 1:\n",
    "                            words = ekedahl_oort_type(gen,data,i,groupSize)\n",
    "\n",
    "\n",
    "                            eoType = final_type(canonical_type(words))\n",
    "                            \n",
    "                            if g*(g+1)/2 - eo_dimension(eoType) > 2*(3*g-3):\n",
    "                            \n",
    "                                if not i in moduli_dict[m]:\n",
    "                                    moduli_dict[m][i] = dict()\n",
    "                                moduli_dict[m][i] = 0\n",
    "\n",
    "                                \n",
    "            else:\n",
    "                \n",
    "                gen_list = alternate_inertial_generators(*data)\n",
    "                for gen in gen_list:\n",
    "                    groupSize = list(gen[0].invariants())\n",
    "                    groupSize.reverse()\n",
    "                    \n",
    "                    if len(groupSize) == 1:\n",
    "                        groupSize.append(1)\n",
    "                    \n",
    "                    groupOrder = groupSize[0]*groupSize[1]\n",
    "                    \n",
    "                    if not groupSize[0] in moduli_dict:\n",
    "                        moduli_dict[groupSize[0]] = dict()\n",
    "                    \n",
    "                    for i in range(1,len(gen)):\n",
    "\n",
    "                        for j in range(1,groupSize[0]):\n",
    "                            \n",
    "                            if gcd(j,groupSize[0]) == 1:\n",
    "                                \n",
    "                                words = ekedahl_oort_type(gen[i],data,j,groupSize)\n",
    "                                \n",
    "                                \n",
    "                                eoType = final_type(canonical_type(words))\n",
    "                                \n",
    "                                if g*(g+1)/2 - eo_dimension(eoType) > 2*(3*g-3):\n",
    "\n",
    "                                    if not j in moduli_dict[groupSize[0]]:\n",
    "                                        moduli_dict[groupSize[0]][j] = dict()\n",
    "                                    moduli_dict[groupSize[0]][j] = 0\n",
    "                                \n",
    "\n",
    "        print(\"Analyzing density\")\n",
    "\n",
    "        density = _compute_moduli(moduli_dict)\n",
    "\n",
    "\n",
    "        data_by_genus.append(density)\n",
    "        print(g,density)\n",
    "        print(\"\")\n",
    "    return data_by_genus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
